---
---

@string{aps = {American Physical Society,}}

@article{alam2024harnessing,
  title={Harnessing traditional controllers for fast-track training of deep reinforcement learning control strategies},
  author={Alam, Md Shadab and Carlucho, Ignacio},
  journal={Journal of Marine Engineering \& Technology},
  pages={1--12},
  year={2024},
  publisher={Taylor \& Francis}
}

@inproceedings{huang2024urobench,
  title={URoBench: Comparative Analyses of Underwater Robotics Simulators from Reinforcement Learning Perspective},
  author={Huang, Zebin and Buchholz, Markus and Grimaldi, Michele and Yu, Hao and Carlucho, Ignacio and Petillot, Yvan R},
  booktitle={OCEANS 2024-Singapore},
  pages={1--8},
  year={2024},
  organization={IEEE}
}

@article{chu2024marinegym,
  title={MarineGym: Accelerated Training for Underwater Vehicles with High-Fidelity RL Simulation},
  author={Chu, Shuguang and Huang, Zebin and Lin, Mingwei and Li, Dejun and Carlucho, Ignacio},
  journal={arXiv preprint arXiv:2410.14117},
  year={2024}
}

@article{yu2024spasticmyoelbow,
  title={SpasticMyoElbow: Physical Human-Robot Interaction Simulation Framework for Modelling Elbow Spasticity},
  author={Yu, Hao and Huang, Zebin and Li, Yutong and Guo, Xinliang and Crocher, Vincent and Carlucho, Ignacio and Erden, Mustafa Suphi},
  journal={arXiv preprint arXiv:2412.04700},
  year={2024}
}

@inproceedings{grimaldi2024fragg,
  title={FRAGG-Map: Frustum Accelerated GPU-Based Grid Map},
  author={Grimaldi, Michele and Palomeras, Narcis and Carlucho, Ignacio and Petillot, Yvan R and Rodriguez, Pere Ridao},
  booktitle={2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={1138--1144},
  year={2024},
  selected={true},
  organization={IEEE}
}

@inproceedings{vecchio2024midgard,
  title={MIDGARD: A Robot Navigation Simulator for Outdoor Unstructured Environments},
  author={Vecchio, Giuseppe and Sarpietro, Riccardo E and Cancelliere, Francesco and Palazzo, Simone and Guastella, Dario C and Strano, Alessandro and Carlucho, Ignacio and Muscato, Giovanni and Albrecht, Stefano V and Spampinato, Concetto},
  booktitle={European Robotics Forum},
  pages={120--125},
  year={2024},
  organization={Springer}
}


@inproceedings{cipolina2023adaptive,
  title={Adaptive Coalition Structure Generation},
  author={Cipolina-Kun, Lucia and Carlucho, Ignacio and Bullard, Kalesha},
  booktitle={Second Agent Learning in Open-Endedness Workshop},
  year={2023}
}

@article{yu2024replication,
  title={Replication of Impedance Identification Experiments on a Reinforcement-Learning-Controlled Digital Twin of Human Elbows},
  author={Yu, Hao and Huang, Zebin and Liu, Qingbo and Carlucho, Ignacio and Erden, Mustafa Suphi},
  journal={arXiv preprint arXiv:2402.02904},
  arxiv={2402.02904},
  year={2024}
}

@article{adetunji2024digital,
  title={Digital Twins Below the Surface: Enhancing Underwater Teleoperation},
  author={Adetunji, Favour O and Ellis, Niamh and Koskinopoulou, Maria and Carlucho, Ignacio and Petillot, Yvan R},
  journal={arXiv preprint arXiv:2402.07556},
  arxiv={2402.07556},
  year={2024}
}

@inproceedings{fosong2024learning,
  title={Learning Complex Teamwork Tasks using a Given Sub-task Decomposition},
  author={Fosong, Elliot and Rahman, Arrasy and Carlucho, Ignacio and Albrecht, Stefano V},
  booktitle={Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems},
  pages={598--606},
  year={2024}
}

@article{alam2023harnessing,
  title={Harnessing Traditional Controllers for Fast-Track Training of Deep Reinforcement Learning Control Strategies},
  author={Alam, Md Shadab and Carlucho, Ignacio},
  year={2023}
}

@inproceedings{nicolay2023enhancing,
      title={Enhancing AUV Autonomy With Model Predictive Path Integral Control}, 
      author={Pierre Nicolay and Yvan Petillot and Mykhaylo Marfeychuk and Sen Wang and Ignacio Carlucho},
      year={2023},
      booktitle={OCEANS 2023},
      organization={IEEE},
      eprint={2308.05547},
      archivePrefix={arXiv},
      primaryClass={cs.RO},
      selected={true},
      abstract={Autonomous underwater vehicles (AUVs) play a crucial role in surveying marine environments, carrying out underwater inspection tasks, and ocean exploration. However, in order to ensure that the AUV is able to carry out its mission successfully, a control system capable of adapting to changing environmental conditions is required. Furthermore, to ensure the robotic platform's safe operation, the onboard controller should be able to operate under certain constraints. In this work, we investigate the feasibility of Model Predictive Path Integral Control (MPPI) for the control of an AUV. We utilise a non-linear model of the AUV to propagate the samples of the MPPI, which allow us to compute the control action in real time. We provide a detailed evaluation of the effect of the main hyperparameters on the performance of the MPPI controller. Furthermore, we compared the performance of the proposed method with a classical PID and Cascade PID approach, demonstrating the superiority of our proposed controller. Finally, we present results where environmental constraints are added and show how MPPI can handle them by simply incorporating those constraints in the cost function.},
      arxiv={2308.05547},

}



@article{fosong2023learning,
  title={Learning Complex Teamwork Tasks using a Sub-task Curriculum},
  author={Fosong, Elliot and Rahman, Arrasy and Carlucho, Ignacio and Albrecht, Stefano V},
  journal={arXiv preprint arXiv:2302.04944},
  year={2023},
  arxiv={2302.04944},
  preview={football_flow.png},
  code={https://github.com/uoe-agents/MEDoE},
  abstract={Training a team to complete a complex task via multi-agent reinforcement learning can be difficult due to challenges such as policy search in a large policy space, and non-stationarity caused by mutually adapting agents. To facilitate efficient learning of complex multi-agent tasks, we propose an approach which uses an expert-provided curriculum of simpler multi-agent sub-tasks. In each sub-task of the curriculum, a subset of the entire team is trained to acquire sub-task-specific policies. The sub-teams are then merged and transferred to the target task, where their policies are collectively fined tuned to solve the more complex target task. We present MEDoE, a flexible method which identifies situations in the target task where each agent can use its sub-task-specific skills, and uses this information to modulate hyperparameters for learning and exploration during the fine-tuning process. We compare MEDoE to multi-agent reinforcement learning baselines that train from scratch in the full task, and with naïve applications of standard multi-agent reinforcement learning techniques for fine-tuning. We show that MEDoE outperforms baselines which train from scratch or use naïve fine-tuning approaches, requiring significantly fewer total training timesteps to solve a range of complex teamwork tasks.s}

}

@article{cipolina2023multi,
  title={Multi-Agent Reinforcement Learning for Coalitional Bargaining Games},
  author={Cipolina-Kun, Lucia and Mak, Stephen and Carlucho, Ignacio and Yazdanpanah, Vahid and Stein, Sebastian and Gerding, Enrico and Bullard, Kalesha},
  year={2023},
  url={https://openreview.net/forum?id=OaZktJBVpUy},
  journal={ICLR 2023 Tiny Papers},
  abstract={In recent years, there has been growing attention to the application of MARL to coalition formation problems, in particular, on coalitional bargaining games as a means of negotiation. However, the lack of theoretical principles for using MARL in coalitional bargaining games remain less explored. This paper aims to address this gap by providing an examination of the theoretical link between coalition formation, coalitional bargaining games, and MARL through the link of stochastic games. Through this analysis, the paper seeks to shed light on the underlying principles that support the use of MARL in coalitional bargaining and to explore the contributions of this approach and its limitations in comparison to traditional game theoretical methods.}

}

@article{Carlucho2022Pred,
author={Carlucho, Ignacio and Stephens, Dylan and Ard, William and Barbalata, Corina},
title={Semi-Parametric Control Architecture for Autonomous Underwater Vehicles Subject to Time Delays},
journal={IEEE Access},
year={2023},
abstract={This paper presents a data-driven model-based control system for autonomous underwater vehicles (or AUVs) subject to input delays. This work is motivated by the input time delays that can arise in underwater robotics due to communication restrictions and sensor malfunctions. Such delays can highly degrade the performance of classical control structures resulting in unpredictable system behaviours. The proposed control architecture addresses such limitations. The approach incorporates a linear dynamic representation of the system obtained using the Koopman operator in an observer/state prediction formulation. The proposed control architecture is designed based on  discrepancies between the data-driven estimation of the system's behaviour and the actual AUV performance using chain predictors.  The capabilities of the proposed approach are shown through experiments performed with a $4$ degrees-of-freedom autonomous underwater vehicle. The results demonstrate  stable behaviours without steady-state errors, even in the presence of long delay.},
preview={dory.png},
selected={true},
}



@article{rahman2022general,
author  = {Arrasy Rahman and Ignacio Carlucho and Niklas Höpner and Stefano V. Albrecht},
title   = {A General Learning Framework for Open Ad Hoc Teamwork Using Graph-based Policy Learning},
journal = {Journal of Machine Learning Research},
year    = {2023},
volume  = {24},
number  = {298},
pages   = {1--74},
url     = {http://jmlr.org/papers/v24/22-099.html},
arxiv={2210.05448},
code={https://github.com/uoe-agents/PO-GPL},
preview={gpl.png},
selected={true},
abstract = {Open ad hoc teamwork is the problem of training a single agent to efficiently collaborate with an unknown group of teammates whose composition may change over time. A variable team composition creates challenges for the agent, such as the requirement to adapt to new team dynamics and dealing with changing state vector sizes. These challenges are aggravated in real-world applications where the controlled agent has no access to the full state of the environment. In this work, we develop a class of solutions for open ad hoc teamwork under full and partial observability. We start by developing a solution for the fully observable case that leverages graph neural network architectures to obtain an optimal policy based on reinforcement learning. We then extend this solution to partially observable scenarios by proposing different methodologies that maintain belief estimates over the latent environment states and team composition. These belief estimates are combined with our solution for the fully observable case to compute an agent's optimal policy under partial observability in open ad hoc teamwork. Empirical results demonstrate that our approach can learn efficient policies in open ad hoc teamwork in full and partially observable cases. Further analysis demonstrates that our methods' success is a result of effectively learning the effects of teammates' actions while also inferring the inherent state of the environment under partial observability.}
}

@article{rahman2023generating,
title={Generating Teammates for Training Robust Ad Hoc Teamwork Agents via Best-Response Diversity},
author={Arrasy Rahman and Elliot Fosong and Ignacio Carlucho and Stefano V Albrecht},
journal={Transactions on Machine Learning Research},
issn={2835-8856},
year={2023},
url={https://openreview.net/forum?id=l5BzfQhROl},
note={},
abstract={ Ad hoc teamwork (AHT) is the challenge of designing a robust learner agent that effectively collaborates with unknown teammates without prior coordination mechanisms. Early approaches address the AHT challenge by training the learner with a diverse set of handcrafted teammate policies, usually designed based on an expert's domain knowledge about the policies the learner may encounter. However, implementing teammate policies for training based on domain knowledge is not always feasible. In such cases, recent approaches attempted to improve the robustness of the learner by training it with teammate policies generated by optimising information-theoretic diversity metrics. The problem with optimising existing information-theoretic diversity metrics for teammate policy generation is the emergence of superficially different teammates. When used for AHT training, superficially different teammate behaviours may not improve a learner's robustness during collaboration with unknown teammates. In this paper, we present an automated teammate policy generation method optimising the Best-Response Diversity (BRDiv) metric, which measures diversity based on the compatibility of teammate policies in terms of returns. We evaluate our approach in environments with multiple valid coordination strategies, comparing against methods optimising information-theoretic diversity metrics and an ablation not optimising any diversity metric. Our experiments indicate that optimising BRDiv yields a diverse set of training teammate policies that improve the learner's performance relative to previous teammate generation approaches when collaborating with near-optimal previously unseen teammate policies.},
arxiv={2207.14138},
bibtex_show={true},
code={https://github.com/uoe-agents/BRDiv},
selected={true},
preview={brdiv.png}
}

@article{Albrecht2022SpecialIssue,
author = {Ahmed, Ibrahim H. and Brewitt, Cillian and Carlucho, Ignacio and Christianos, Filippos and Dunion, Mhairi and Fosong, Elliot and Garcin, Samuel and Guo, Shangmin and Gyevnar, Balint      and McInroe, Trevor and Papoudakis, Georgios and Rahman, Arrasy and Schäfer, Lukas and Tamborski, Massimiliano and Vecchio, Giuseppe and Wang, Cheng and Albrecht, Stefano V.},
title = {Deep Reinforcement Learning for Multi-Agent Interaction},
journal = {AI Communications (AIC)},
year = {2022},
month={May},
arxiv={2208.01769},
abstrac={The development of autonomous agents which can interact with other agents to accomplish a given task is a core area of research in artificial intelligence and machine learning. Towards this goal, the Autonomous Agents Research Group develops novel machine learning algorithms for autonomous systems control, with a specific focus on deep reinforcement learning and multi-agent reinforcement learning. Research problems include scalable learning of coordinated agent policies and inter-agent communication; reasoning about the behaviours, goals, and composition of other agents from limited observations; and sample-efficient learning based on intrinsic motivation, curriculum learning, causal inference, and representation learning. This article provides a broad overview of the ongoing research portfolio of the group and discusses open problems for future directions. },
code={https://github.com/uoe-agents},
preview={aeg.jpg}
}
               

@Article{Morgan2022,
author={Morgan, Edward
and Carlucho, Ignacio
and Ard, William
and Barbalata, Corina},
title={Autonomous Underwater Manipulation: Current Trends in Dynamics, Control, Planning, Perception, and Future Directions},
journal={Current Robotics Reports},
year={2022},
month={Feb},
day={27},
abstract={Research in underwater manipulation has mostly focused on solving individual parts of the manipulation challenge; however, we believe a systemic approach needs to be taken to achieve full autonomy. With this survey, we aim to provide a review of the different dynamic modeling, control, motion planning, and perception methodologies presented in the literature, and, more importantly, we intend to highlight the necessary steps that need to be taken to achieve fully autonomous underwater manipulation.},
issn={2662-4087},
doi={10.1007/s43154-022-00089-2},
url={https://doi.org/10.1007/s43154-022-00089-2},
altmetric={true},
dimensions={true},
preview={dory_tank.png}
}


@inproceedings{willners2021market,
  title={From market-ready {ROVs} to low-cost {AUVs}},
  author={Willners, Jonatan Scharff and Carlucho, Ignacio and Katagiri, Sean and Lemoine, Chandler and Roe, Joshua and Stephens, Dylan and {\L}uczy{\'n}ski, Tomasz and Xu, Shida and Carreno, Yaniel and Pairet, {\`E}ric and others},
  booktitle={OCEANS 2021: San Diego--Porto},
  pages={1--7},
  year={2021},
  organization={IEEE},
  arxiv={2108.05792},
  preview={market.png}
}

@article{mirsky2022survey,
  title={A Survey of Ad Hoc Teamwork: Definitions, Methods, and Open Problems},
  author={Mirsky, Reuth and Carlucho, Ignacio and Rahman, Arrasy and Fosong, Elliot and Macke, William and Sridharan, Mohan and Stone, Peter and Albrecht, Stefano V},
  journal={European Conference on Multi-Agent Systems (EUMAS)},
  year={2022},
  month={September},
  arxiv={2202.10450},
  abstract={Ad hoc teamwork is the research problem of designing agents that can collaborate with new teammates without prior coordination. This survey makes a two-fold contribution: First, it provides a structured description of the different facets of the ad hoc teamwork problem. Second, it discusses the progress that has been made in the field so far, and identifies the immediate and long-term open problems that need to be addressed in ad hoc teamwork. },
  selected={false},
}


@inproceedings{nguyen2022robotic,
  title={Robotic Manipulators Performing Smart Sanding Operation: A Vibration Approach},
  author={Nguyen, Joshua and Bailey, Manuel and Carlucho, Ignacio and Barbalata, Corina},
  booktitle={2022 International Conference on Robotics and Automation (ICRA)},
  pages={2958--2964},
  year={2022},
  organization={IEEE},
  month={Feb},
  abstract={This paper presents the design of a novel expert system for robotic manipulators performing sanding tasks on work surfaces. The expert system adjusts the velocity of the robotic manipulator based on the observed surface quality. These observation are obtained by an analysis of the raw force data provided by a force-torque sensor at the end-effector level. The expert system consists of two governing control laws that act in parallel, a variable velocity generation law and a pose regulation-based law. The variable velocity law regulates the velocity of the manipulator along a set path, in the tangent direction, based on an analysis of the frequency and amplitude of the force signal generated during the sanding process. The pose regulation-based law drives the manipulator in the bi-normal and rotational direction, ensuring the manipulators remain on the sanding path with the desired orientation. The proposed strategy is experimentally evaluated using the UR5e collaborative robotic manipulator sanding wood and metal panels. The obtained results show that such an approach is beneficial to ensure accurate contact between the sanding tool and the working environment, robust path tracking, and smart sanding.},
  preview={arm_sand.png}
}


        

    
@inproceedings{vecchio2022midgard,
  title={MIDGARD: A Simulation Platform for Autonomous Navigation in Unstructured Environments},
  author={Vecchio, Giuseppe and Palazzo, Simone and Guastella, Dario C and Carlucho, Ignacio and Albrecht, Stefano V and Muscato, Giovanni and Spampinato, Concetto},
  booktitle={ICRA Workshop on Releasing Robots into the Wild: Simulations, Benchmarks, and Deployment (ICRA)},
  year={2022},
  arxiv={2205.08389},
  abstract={We present MIDGARD, an open-source simulation platform for autonomous robot navigation in outdoor unstructured environments. MIDGARD is designed to enable the training of autonomous agents (e.g., unmanned ground vehicles) in photorealistic 3D environments, and to support the generalization skills of learning-based agents through the variability in training scenarios. MIDGARD's main features include a configurable, extensible, and difficulty-driven procedural landscape generation pipeline, with fast and photorealistic scene rendering based on Unreal Engine. Additionally, MIDGARD has built-in support for OpenAI Gym, a programming interface for feature extension (e.g., integrating new types of sensors, customizing exposing internal simulation variables), and a variety of simulated agent sensors (e.g., RGB, depth and instance/semantic segmentation). We evaluate MIDGARD's capabilities as a benchmarking tool for robot navigation utilizing a set of state-of-the-art reinforcement learning algorithms. The results demonstrate MIDGARD's suitability as a simulation and training environment, as well as the effectiveness of our procedural generation approach in controlling scene difficulty, which directly reflects on accuracy metrics.},
  website={https://midgardsim.org/},
  preview={thumbnail.png}
}

@inproceedings{carlucho2020reinforcement,
  title={A reinforcement learning control approach for underwater manipulation under position and torque constraints},
  author={Carlucho, Ignacio and De Paula, Mariano and Barbalata, Corina and Acosta, Gerardo G},
  booktitle={Global Oceans 2020: Singapore--US Gulf Coast},
  pages={1--7},
  year={2020},
  organization={IEEE}
}

@inproceedings{carlucho2020insights,
  title={Insights into a data driven optimal control for energy efficient manipulation},
  author={Carlucho, Ignacio and Stephens, Dylan W and Barbalata, Corina},
  booktitle={Global Oceans 2020: Singapore--US Gulf Coast},
  pages={1--6},
  year={2020},
  organization={IEEE}
}

@article{carlucho2021adaptive,
  title={An adaptive data-driven controller for underwater manipulators with variable payload},
  author={Carlucho, Ignacio and Stephens, Dylan W and Barbalata, Corina},
  journal={Applied Ocean Research},
  volume={113},
  pages={102726},
  year={2021},
  publisher={Elsevier},
  doi={https://doi.org/10.1016/j.apor.2021.102726},
  altmetric={true},
  dimensions={true},
  preview={bluerov_reach5.jpg}
}

@article{carlucho2019hybrid,
  title={A hybrid reinforcement learning perspective for autonomous mobile robot control},
  author={Carlucho, Ignacio},
  year={2019}
}

@inproceedings{carlucho2021marine,
  title={Marine Vehicles Localization Using Grid Cells for Path Integration},
  author={Carlucho, Ignacio and Bailey, Manuel F and De Paula, Mariano and Barbalata, Corina},
  booktitle={OCEANS 2021: San Diego--Porto},
  pages={1--6},
  year={2021},
  organization={IEEE},
  arxiv={2107.13461},
  abstract={Autonomous Underwater Vehicles (AUVs) are platforms used for research and exploration of marine environments. However, these types of vehicles face many challenges that hinder their widespread use in the industry. One of the main limitations is obtaining accurate position estimation, due to the lack of GPS signal underwater. This estimation is usually done with Kalman filters. However, new developments in the neuroscience field have shed light on the mechanisms by which mammals are able to obtain a reliable estimation of their current position based on external and internal motion cues. A new type of neuron, called Grid cells, has been shown to be part of path integration system in the brain. In this article, we show how grid cells can be used for obtaining a position estimation of underwater vehicles. The model of grid cells used requires only the linear velocities together with heading orientation and provides a reliable estimation of the vehicle's position. We provide simulation results for an AUV which show the feasibility of our proposed methodology.},
}

@article{leegstra2019macabot,
  title={Mac{\'a}bot: Prototipo de veh{\'\i}culo aut{\'o}nomo de superficie (asv)},
  author={Leegstra, Roberto C and De Paula, Mariano and Carlucho, Ignacio and Solari, Franco J and Rozenfeld, Alejandro F and Acosta, Gerardo G and Menna, Bruno V and Roberto, J and Arrien, Luis M and Curti, Hugo J and others},
  journal={Revista Tecnolog{\'\i}a y Ciencia},
  number={36},
  pages={142--154},
  year={2019}
}

@article{oubre2021data,
  title={Data-driven controllers and the need for perception systems in underwater manipulation},
  author={Oubre, James P and Carlucho, Ignacio and Barbalata, Corina},
  journal={ICRA Workshop on Marine Robotics: Active Perception (ICRA)},
  year={2021}
}





@inproceedings{carlucho2022cooperative,
              title={Cooperative Marine Operations Via Ad Hoc Teams}, 
              author={Ignacio Carlucho and Arrasy Rahman and William Ard and Elliot Fosong and Corina Barbalata and Stefano V. Albrecht},
              year={2022},
              booktitle={IJCAI Workshop on Ad Hoc Teamwork},
              arxiv={2207.07498},
              abstract={While research in ad hoc teamwork has great potential for solving real-world robotic applications, most developments so far have been focusing on environments with simple dynamics. In this article, we discuss how the problem of ad hoc teamwork can be of special interest for marine robotics and how it can aid marine operations. Particularly, we present a set of challenges that need to be addressed for achieving ad hoc teamwork in underwater environments and we discuss possible solutions based on current state-of-the-art developments in the ad hoc teamwork literature. },
        }
        
@inproceedings{fosong2022few,
       title={Few-Shot Teamwork},
       author={Elliot Fosong and Arrasy Rahman and Ignacio Carlucho and Stefano V. Albrecht},
     abstract = {We propose the novel few-shot teamwork (FST) problem, where skilled agents trained in a team to complete one task are combined with skilled agents from different tasks, and together must learn to adapt to an unseen but related task. We discuss how the FST problem can be seen as addressing two separate problems: one of reducing the experience required to train a team of agents to complete a complex task; and one of collaborating with unfamiliar teammates to complete a new task. Progress towards solving FST could lead to progress in both multi-agent reinforcement learning and ad hoc teamwork.},
       booktitle={IJCAI Workshop on Ad Hoc Teamwork},
       year={2022},
       preview={football_flow.png}
    }

@inproceedings{Rahman2022TG,
       title={Towards Robust Ad Hoc Teamwork Agents By Creating Diverse Training Teammates},
       author={Arrasy Rahman and Elliot Fosong and Ignacio Carlucho and Stefano V. Albrecht},
     booktitle={IJCAI Workshop on Ad Hoc Teamwork},
       year={2022}
    }
    

@article{avila2019mppt,
  title={{MPPT} for {PV} systems using deep reinforcement learning algorithms},
  author={Avila, Luis and De Paula, Mariano and Carlucho, Ignacio and Reinoso, Carlos Sanchez},
  journal={IEEE Latin America Transactions},
  volume={17},
  number={12},
  pages={2020--2027},
  year={2019},
  publisher={IEEE}
}

@inproceedings{meira2020dga,
  title={{DGA}: A novel strategy for key gases identification in power transformers},
  author={Meira, Matias and Carlucho, Ignacio and {\'A}lvarez, Ra{\'u}l and Catalano, Leonardo and Acosta, Gerardo},
  booktitle={2020 IEEE Electrical Insulation Conference (EIC)},
  pages={290--293},
  year={2020},
  organization={IEEE}
}

@article{avila2020deep,
  title={Deep reinforcement learning approach for {MPPT} control of partially shaded {PV} systems in Smart Grids},
  author={Avila, Luis and De Paula, Mariano and Trimboli, Maximiliano and Carlucho, Ignacio},
  journal={Applied Soft Computing},
  volume={97},
  pages={106711},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{acosta2019ictiobot,
  title={{ICTIOBOT-40} a low cost AUV platform for acoustic imaging surveying},
  author={Acosta, Gerardo G and Menna, Bruno V and Carlucho, Ignacio and De Paula, Mariano and Villar, Sebastian A and Curti, Hugo J and Rozenfeld, Alejandro F and Roberto, J and Isasmendi, Agustin and Leegstra, Roberto C and others},
  booktitle={OCEANS 2019-Marseille},
  pages={1--10},
  year={2019},
  organization={IEEE}
}

@article{acosta2017macabot,
  title={Macabot: prototipo de vehiculo autonomo de superficie ({ASV})},
  author={Acosta, GG and Menna, B and de La Vega, R and Arrien, L and Curti, H and Villar, S and Leegstra, R and Paula, MD and Carlucho, I and Solari, F and others},
  journal={XI Jornadas Argentinas de Robotica},
  year={2017}
}



@article{carlucho2020adaptive,
  title={An adaptive deep reinforcement learning approach for {MIMO} {PID} control of mobile robots},
  author={Carlucho, Ignacio and De Paula, Mariano and Acosta, Gerardo G},
  journal={ISA transactions},
  volume={102},
  pages={280--294},
  year={2020},
  publisher={Elsevier},
  doi={https://doi.org/10.1016/j.isatra.2020.02.017},
  altmetric={true},
  dimensions={true},
  preview={adaptive_mimo.jpg}
}



@article{carlucho2017incremental,
  title={Incremental {Q-learning} strategy for adaptive {PID} control of mobile robots},
  author={Carlucho, Ignacio and De Paula, Mariano and Villar, Sebastian A and Acosta, Gerardo G},
  journal={Expert Systems with Applications},
  volume={80},
  pages={183--199},
  year={2017},
  publisher={Elsevier},
  doi={https://doi.org/10.1016/j.eswa.2017.03.002},
  altmetric={true},
  dimensions={true},
  preview={Pioneer_3at.jpg}
}

@inproceedings{carlucho2016comparison,
  title={Comparison of a {PID} controller versus a {LQG} controller for an autonomous underwater vehicle},
  author={Carlucho, Ignacio and Menna, Bruno and De Paula, Mariano and Acosta, Gerardo G},
  booktitle={2016 3rd IEEE/OES South American International Symposium on Oceanic Engineering (SAISOE)},
  pages={1--6},
  year={2016},
  organization={IEEE}
}

@article{carlucho2018adaptive,
  title={Adaptive low-level control of autonomous underwater vehicles using deep reinforcement learning},
  author={Carlucho, Ignacio and De Paula, Mariano and Wang, Sen and Petillot, Yvan and Acosta, Gerardo G},
  journal={Robotics and Autonomous Systems},
  volume={107},
  pages={71--86},
  year={2018},
  publisher={North-Holland},
  doi={10.1016/j.robot.2018.05.016},
  altmetric={45011323},
  dimensions={true},
    preview={nessie.png}
}

@inproceedings{carlucho2018auv,
  title={{AUV} Position Tracking Control Using End-to-End Deep Reinforcement Learning},
  author={Carlucho, Ignacio and De Paula, Mariano and Wang, Sen and Menna, Bruno V and Petillot, Yvan R and Acosta, Gerardo G},
  booktitle={OCEANS 2018 MTS/IEEE Charleston},
  pages={1--8},
  year={2018},
  organization={IEEE},
  preview={AUV_3d.png}
}

@inproceedings{gianibelli2018obstacle,
  title={An obstacle avoidance system for mobile robotics based on the virtual force field method},
  author={Gianibelli, Agust{\'\i}n and Carlucho, Ignacio and De Paula, Mariano and Acosta, Gerardo G},
  booktitle={2018 IEEE Biennial Congress of Argentina (ARGENCON)},
  pages={1--8},
  year={2018},
  organization={IEEE}
}

@inproceedings{carlucho2018modular,
  title={A Modular Battery Management System for Electric Vehicles},
  author={Carlucho, Ignacio and de la Vega, Roberto and Spina, Marcelo and Acosta, Gerardo G},
  booktitle={2018 IEEE Biennial Congress of Argentina (ARGENCON)},
  pages={1--6},
  year={2018},
  organization={IEEE}
}

@article{carlucho2019double,
  title={Double {Q-PID} algorithm for mobile robot control},
  author={Carlucho, Ignacio and De Paula, Mariano and Acosta, Gerardo G},
  journal={Expert Systems with Applications},
  volume={137},
  pages={292--307},
  year={2019},
  publisher={Pergamon},
  doi={https://doi.org/10.1016/j.eswa.2019.06.066},
  altmetric={45011323},
  dimensions={true},
  preview={double.jpg}
}
